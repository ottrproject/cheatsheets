---
output:
  html_document:
    number_sections: false
    includes:
      in_header: itn_favicon.html
css: css/ITN_style.css
---

```{r, echo=FALSE, results='asis'}
ottrpal::borrow_chapter(
  doc_path = "chunks/create_itn_header.md",
  tag_replacement = list(
    "{TITLE}" = "AI", 
    "{SUBTITLE}" =  "Everyday Uses",
    "{PATH_TO_PNG}" = "https://raw.githubusercontent.com/ottrproject/cheatsheets/refs/heads/main/pngs/cicd.png"
    ))
```

<hr>



<div class="row">
# Suggested AI Uses for Research Tasks
<div class="column">

**Ideation** <img src="https://www.iconpacks.net/icons/2/free-icon-bulb-3658.png" width = 8%>

- Planning code or projects
- Recommending project names or acronyms
- Confirming novel relationships or research ideas
- Mining the literature for research ideas [example](https://www.researchrabbit.ai/)

**Text** <img src=" https://www.iconpacks.net/icons/2/free-icon-news-4300.png" width = 6%>

- Summarizing documents or content
- Combining documents
- Transforming format (e.g. text to table)
- Searching & navigating text
- Adjusting communication


**Visual Design** <img src="https://www.iconpacks.net/icons/1/free-icon-arrow-chart-673.png" width = 8%>

  - Creating flyers for outreach
  - Creating presentation graphics
  - Creating logos
  (Keep in mind that graphic artists are still a great option too!)
  
</div>

<div class="column">


**Code** <img src="https://www.iconpacks.net/icons/4/free-icon-laptop-settings-12589.png" width = 8%>

- Planning steps
- Refactoring code
- Annotating code
- Writing documentation
- Checking for security or privacy concerns
- Understanding someone else's code
- Understanding errors
- Proposing code validation/testing ideas
- Translating code to a new language



**Project Management** <img src="https://www.iconpacks.net/icons/1/free-icon-user-group-296.png" width = 8%>

- Developing templates
- Breaking down tasks
- Assigning roles
- Creating meeting agendas and summaries
- Creating lab document drafts
  - Code of conduct
  - Mentee Agreement 
  - Lab Handbook

</div>
</div>

<hr>



# Tips for AI Use

- Don't use prompts that would violate data privacy restrictions or licensing (most commercial tools are not private!)
- Be specific and iterate on prompts
- Where possible work in an environment that allows for projects to retain the context
- Typically asking AI to improve existing work is better than starting from scratch
- Check everything! Ask the AI to question itself and have a human (maybe you) review text and code

```{r, fig.align='center', out.width="80%", echo = FALSE, fig.alt= "example of more precise ai prompt - can you improve the paragraph is vague, can you make the paragraph more concise is better, can you make the paragraph more concise and appropriate for a highschool student is even better"}
ottrpal::include_slide("https://docs.google.com/presentation/d/1T88OS5ih3l0Ug0MkQpjzM8VwE8MEtecHw02szii4Zz8/edit?slide=id.g360359edea5_0_77#slide=id.g360359edea5_0_77")
```

</div>

<hr>





# Challenges and Mitigation Methods


<div class = myStyle>
|Challenge|Mitigation Methods| Resources/Tools|
|----|-----|-----|
|**Giving Credit**  <br><br> Other people's work was used to train models sometimes without permission. | ● Choose tools that are more transparent about [what data was used for training](https://www.transparencycoalition.ai/news/major-ai-transparency-breakthrough-ai2-model-displays-training-data-sources-linked-to-output) <br> ● Be transparent about how you use AI tools, include tool versions <br> ● Ask the tool for sources to credit and check what it gives  you <br>  | ● Check out  [IBM's AI attribution toolkit](https://aiattribution.github.io/) <br> ● Consider tools like [OLMoTrace](https://allenai.org/blog/olmotrace) which show what training was used for the AI response
|**Data Privacy** <br><br> Some tools are using data that should not have been available| ● Choose tools that are more transparent about [what data was used for training](https://www.transparencycoalition.ai/news/major-ai-transparency-breakthrough-ai2-model-displays-training-data-sources-linked-to-output) <br> ● Look into those data sources and see if they followed data privacy regulations. <br> ● Never use private data or info in a prompt for a commercial tool| ● See if your institute offers private tools <br> ● Models run locally may be more private |
|**Environmental Impact** <br><br> AI tools use data centers that require lots of electricity and water for cooling.| ● Consider if AI is the best tool for the task <br> ● Choose AI tools that are transparent about energy use and attempt to improve efficiency <br> ● Choose models that use a smaller number of parameters, designed with methods like [parameter-efficient fine-tuning (PEFT)](https://huggingface.co/blog/peft), or simply designed for more specific tasks and therefore often requiring less memory usage <br> ● Consider using a [model locally on your computer](https://www.ainewshub.org/post/top-9-open-source-ai-models-you-can-run-on-your-own-pc-right-now-2025-edition-updated)  <br> ● Consider tools with data centers in cooler climate locations or those that use the heat that is generated for other uses| ● [GreenPT](https://greenpt.ai/) is a very eco-concious  tool <br> ● [Ollama](https://mehmetozkaya.medium.com/installing-and-running-llama-and-gemma-models-using-ollama-4c7027ec948c) can help you run models like [Gemma 2](https://huggingface.co/google/gemma-2-2b-it), [Mistral AI](https://mistral.ai/), [Phi-4](https://huggingface.co/microsoft/phi-4) locally <br> ● [Offset AI](https://www.ecolytics.io/blog/ecolytics-launches-offset-ai-the-first-tool-to-track-and-offset-the-environmental-impact-of-artificial-intelligence-usage) is a tool to help track and offset the environmental impact of your AI usage|
|**Trust and Deskilling** <br><br> Using AI too much can degrade trust in yourself and potentially result in the loss of [skills you once had](https://www.thelancet.com/journals/langas/article/PIIS2468-1253(25)00133-5/fulltext).| ● Use AI for more specific help, like polishing as opposed to writing things from scratch <br> ● Use AI only when it is likely to save you time or tedium  <br> ● Check in with trainees about AI use |● Check out this paper where humans were shown to [overtrust AI](https://www.nature.com/articles/s41591-020-0942-0) <br> ● Check out this paper where [developers thought AI made them faster](https://arxiv.org/pdf/2507.09089)|
|**Distorted responses and Hallucinations** <br><br> Even simple requests can generate false or skewed responses| ● Check for errors <br> ● Ask tools to consider the potential for distorted responses in your prompts <br> ● Challenge tools when they fail to recognize errors <br> ● Recognize that human oversight is necessary | ● Check out this [resource from MIT](https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/)|

<!-- bullet from https://www.madeintext.com/bullet-point/ -->

</div>







<hr>

# Resources

- Read more about why [small models](https://www.computer.org/publications/tech-news/community-voices/sustainable-future-of-ai-language-models) may be the future for more sustainable AI
- Check out more [about PEFT for efficiency](https://codewave.com/insights/parameter-efficient-fine-tuning-peft-methods/)
- Read more about the [MIT AI data provenance initiative](https://mitsloan.mit.edu/ideas-made-to-matter/bringing-transparency-to-data-used-to-train-artificial-intelligence)
- These ITN courses discuss more about AI use for research and coding: 
  - [AI for Decision Makers](https://hutchdatascience.org/ITN_course_search/AI_for_Decision_Makers_coursePage.html) which includes a mini course about [AI Ethics](https://hutchdatascience.org/AI_for_Decision_Makers/introduction-to-avoiding-ai-harm.html)
  - [AI for Efficient Programming](https://hutchdatascience.org/ITN_course_search/AI_for_Efficient_Programming_coursePage.html)



```{r, echo=FALSE, results='asis'}
ottrpal::borrow_chapter(
  doc_path = "chunks/create_itn_footer.md",
  tag_replacement = list(
    "{AUTHORS}" = "Content for this cheatsheet came from  Carrie Wright. It was summarized and formatted by Carrie Wright and reviewed by Kate Isaac. Icons from https://www.iconpacks.net. The cheatsheet was also inspired by a discussion that involved the ITCR OPEN community (https://www.itcrtraining.org/open)."))
```

